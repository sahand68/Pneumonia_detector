{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iuAn053WZat"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pylab as plt\n",
    "import pydicom\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "import random\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QHDa2uOWZa1"
   },
   "source": [
    "# ChexNet\n",
    "[Stanford ChexNet](https://arxiv.org/abs/1711.05225)\n",
    "\n",
    "### Radiology \n",
    "* The ***ChexNet*** paper reviews performance of AI versus 4 trained radiologists in diagnosing pneumonia. \n",
    "* **Pneumonia is a clinical diagnosis** — a **patient** will present with **fever and cough** , and can get a **chest Xray(CXR) to identify complications of pneumonia.** Patients will usually get **blood cultures** to **supplement diagnosis. Pneumonia on a CXR** is not easily distinguishable from other findings that fill the **alevolar spaces  —  specifically pus , blood , fluid or collapsed lung called atelectasis.**   \n",
    "* The radiologists interpreting these studies can therefore use terms like infiltrates , consolidation and atelectasis interchangeably.\n",
    "\n",
    "### Architeture of ChexNet( from [Stanford ChexNet](https://arxiv.org/abs/1711.05225))\n",
    "* The **CheXNet algorithm** is a **121-layer deep 2D Convolutional Neural Network;** a **Densenet** after **Huang & Liu**. **The Densenet’s multiple residual connections reduce parameters and training time**, allowing a deeper, more powerful model. The model accepts a vectorized ***two-dimensional image of size 224 pixels by 224 pixels.***\n",
    "\n",
    "* To improve trust in CheXNet’s output, a Class Activation Mapping (GRAD-CAM) heatmap was utilized after [Zhou et al](https://people.csail.mit.edu/bzhou/publication/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf). This allows the human user to “see” what areas of the radiograph provide the strongest activation of the Densenet for the highest probability label.  \n",
    "* CheXNet is a 121-layer Dense Convolutional Network (DenseNet) (Huang et al., 2016) trained on the ChestX-ray 14 dataset. DenseNets improve flow of information and gradients through the network, making the optimization of very deep networks tractable. We replace the final fully connected layer with one that has a single output, after which we apply a sigmoid nonlinearity. The weights of the network are initialized with weights from a model pretrained on ImageNet (Deng et al., 2009). The network is trained end-to-end using Adam with standard parameters (ß1 = 0.9 and ß2 = 0.999) (Kingma & Ba, 2014). We train the model using minibatches of size 16. We use an initial learning rate of 0.001 that is decayed by a factor of 10 each time the validation loss plateaus after an epoch, and pick the model with the lowest validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ExQ-YBY2WZa3"
   },
   "source": [
    "# Display Images for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywOj_Sd7WZa9"
   },
   "outputs": [],
   "source": [
    "# Forked from `https://www.kaggle.com/peterchang77/exploratory-data-analysis`\n",
    "def parse_data(df, test = False):\n",
    "    \"\"\"\n",
    "    Method to read a CSV file (Pandas dataframe) and parse the \n",
    "    data into the following nested dictionary:\n",
    "\n",
    "      parsed = {\n",
    "        \n",
    "        'patientId-00': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        },\n",
    "        'patientId-01': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        }, ...\n",
    "\n",
    "      }\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Define lambda to extract coords in list [y, x, height, width]\n",
    "    extract_box = lambda row: [row['y'], row['x'], row['height'], row['width']]\n",
    "\n",
    "    parsed = {}\n",
    "    if not test:\n",
    "      for n, row in df.iterrows():\n",
    "          # --- Initialize patient entry into parsed \n",
    "          pid = row['patientId']\n",
    "          if pid not in parsed:\n",
    "              parsed[pid] = {\n",
    "                  'dicom': 'data/stage_2_train_images/%s.dcm' % pid,\n",
    "                  'label': row['Target'],\n",
    "                  'boxes': []}\n",
    "\n",
    "          # --- Add box if opacity is present\n",
    "          if parsed[pid]['label'] == 1:\n",
    "              parsed[pid]['boxes'].append(extract_box(row))\n",
    "    else:\n",
    "      for n, row in df.iterrows():\n",
    "          # --- Initialize patient entry into parsed \n",
    "          pid = row['patientId']\n",
    "          if pid not in parsed:\n",
    "              parsed[pid] = {\n",
    "                  'dicom': 'uploads/%s.dcm' % pid,\n",
    "                  'label': row['Target'],\n",
    "                  'boxes': []}\n",
    "\n",
    "          # --- Add box if opacity is present\n",
    "          if parsed[pid]['label'] == 1:\n",
    "              parsed[pid]['boxes'].append(extract_box(row))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def draw(data):\n",
    "    \"\"\"\n",
    "    Method to draw single patient with bounding box(es) if present \n",
    "\n",
    "    \"\"\"\n",
    "    # --- Open DICOM file\n",
    "    d = pydicom.read_file(data['dicom'])\n",
    "    im = d.pixel_array\n",
    "\n",
    "    # --- Convert from single-channel grayscale to 3-channel RGB\n",
    "    im = np.stack([im] * 3, axis=2)\n",
    "\n",
    "    # --- Add boxes with random color if present\n",
    "    for box in data['boxes']:\n",
    "        #rgb = np.floor(np.random.rand(3) * 256).astype('int')\n",
    "        rgb = [255, 251, 204] # Just use yellow\n",
    "        im = overlay_box(im=im, box=box, rgb=rgb, stroke=15)\n",
    "\n",
    "    plt.imshow(im, cmap=plt.cm.gist_gray)\n",
    "    plt.axis('off')\n",
    "\n",
    "def overlay_box(im, box, rgb, stroke=2):\n",
    "    \"\"\"\n",
    "    Method to overlay single box on image\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Convert coordinates to integers\n",
    "    box = [int(b) for b in box]\n",
    "    \n",
    "    # --- Extract coordinates\n",
    "    y1, x1, height, width = box\n",
    "    y2 = y1 + height\n",
    "    x2 = x1 + width\n",
    "\n",
    "    im[y1:y1 + stroke, x1:x2] = rgb\n",
    "    im[y2:y2 + stroke, x1:x2] = rgb\n",
    "    im[y1:y2, x1:x1 + stroke] = rgb\n",
    "    im[y1:y2, x2:x2 + stroke] = rgb\n",
    "\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1578161458126,
     "user": {
      "displayName": "sahand azad",
      "photoUrl": "https://lh6.googleusercontent.com/-o867s7QeY4M/AAAAAAAAAAI/AAAAAAAAWoc/XLta5OuiE4M/s64/photo.jpg",
      "userId": "02116279255621625687"
     },
     "user_tz": 480
    },
    "id": "i0c8jVE9WZbK",
    "outputId": "db302b39-b745-4d59-d33a-c3cb8f4a9e2f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class generator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, folder, filenames, nodule_locations=None, batch_size=32, image_size=512, shuffle=True, predict=False, augment = False):\n",
    "        self.folder = folder\n",
    "        self.filenames = filenames\n",
    "        self.nodule_locations = nodule_locations\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.predict = predict\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # create empty mask\n",
    "        msk = np.zeros(img.shape)\n",
    "        # get filename without extension\n",
    "        filename = filename.split('.')[0]\n",
    "        # if image contains nodules\n",
    "        if filename in nodule_locations:\n",
    "            # loop through nodules\n",
    "            for location in nodule_locations[filename]:\n",
    "                # add 1's at the location of the nodule\n",
    "                x, y, w, h = location\n",
    "                msk[y:y+h, x:x+w] = 1\n",
    "        # resize both image and mask\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n",
    "        # if augment then horizontal flip half the time\n",
    "        if self.augment and random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "            msk = np.fliplr(msk)\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        msk = np.expand_dims(msk, -1)\n",
    "        return img, msk\n",
    "    \n",
    "    def __loadpredict__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # resize image\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # select batch\n",
    "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # predict mode: return images and filenames\n",
    "        if self.predict:\n",
    "            # load files\n",
    "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            return imgs, filenames\n",
    "        # train mode: return images and masks\n",
    "        else:\n",
    "            # load files\n",
    "            items = [self.__load__(filename) for filename in filenames]\n",
    "            # unzip images and masks\n",
    "            imgs, msks = zip(*items)\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            msks = np.array(msks)\n",
    "            return imgs, msks\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.filenames)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.predict:\n",
    "            # return everything\n",
    "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
    "        else:\n",
    "            # return full batches only\n",
    "            return int(len(self.filenames) / self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxElt9ecWZbL"
   },
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    smooth = tf.ones(tf.shape(intersect))\n",
    "    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n",
    "def create_downsample(channels, inputs):\n",
    "    x = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU(0)(x)\n",
    "    x = tf.keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "    return x\n",
    "\n",
    "def create_resblock(channels, inputs):\n",
    "    x = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU(0)(x)\n",
    "    x = tf.keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0)(x)\n",
    "    x = tf.keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    return tf.keras.layers.add([x, inputs])\n",
    "\n",
    "def create_network(input_size, channels, n_blocks=2, depth=5):\n",
    "    # input\n",
    "    inputs = tf.keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = tf.keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n",
    "    # residual blocks\n",
    "    for d in range(depth):\n",
    "        channels = channels * 2\n",
    "        x = create_downsample(channels, x)\n",
    "        for b in range(n_blocks):\n",
    "            x = create_resblock(channels, x)\n",
    "    # output\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0)(x)\n",
    "    x = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    outputs = tf.keras.layers.UpSampling2D(2**depth)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1739958,
     "status": "ok",
     "timestamp": 1578128465539,
     "user": {
      "displayName": "sahand azad",
      "photoUrl": "https://lh6.googleusercontent.com/-o867s7QeY4M/AAAAAAAAAAI/AAAAAAAAWoc/XLta5OuiE4M/s64/photo.jpg",
      "userId": "02116279255621625687"
     },
     "user_tz": 480
    },
    "id": "WAuAS4aX9XMK",
    "outputId": "2edaca1e-7200-421f-ca5e-af5e5fc5db06"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-5-03a09c5cae21>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-03a09c5cae21>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "    folder = 'uploads'\n",
    "    test_filenames = os.listdir(folder)\n",
    "    print('n test samples:', len(test_filenames))\n",
    "    k_=[]\n",
    "    x_= []\n",
    "    y_ =[]\n",
    "    w_ =[]\n",
    "    h_ =[]\n",
    "    t_= []\n",
    "    area = []\n",
    "    # create test generator with predict flag set to True\n",
    "    test_gen = generator(folder, test_filenames, None, batch_size=25, image_size=256, shuffle=False, predict=True)\n",
    "    submission_dict={}\n",
    "    predictions =pd.DataFrame()\n",
    "    for imgs, filenames in test_gen:\n",
    "        # predict batch of images\n",
    "        model = create_network(input_size=256, channels=32, n_blocks=2, depth=4)\n",
    "        model.load_weights(\"model/model.h5\")\n",
    "        preds = model.predict(imgs)\n",
    "        for pred, filename in zip(preds, filenames):\n",
    "            # resize predicted mask\n",
    "            pred = resize(pred, (1024, 1024), mode='reflect')\n",
    "            # threshold predicted mask\n",
    "            comp = pred[:, :, 0]>0.5\n",
    "            # apply connected components\n",
    "            comp = measure.label(comp)\n",
    "            # apply bounding boxes\n",
    "            predictionString = ''\n",
    "            for region in measure.regionprops(comp):\n",
    "                # retrieve x, y, height and width\n",
    "                y, x, y2, x2 = region.bbox\n",
    "                height = y2 - y\n",
    "                k_.append(filename.split('.')[0])\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "                h_.append(height)\n",
    "                width = x2 - x\n",
    "                w_.append(width)\n",
    "                conf = np.mean(pred[y:y+height, x:x+width])\n",
    "                area.append(width*height)\n",
    "                t_.append(conf)\n",
    "        if len(x_) >= len(test_filenames):\n",
    "            break\n",
    "    test_predictions = pd.DataFrame()\n",
    "    test_predictions['patientId'] = k_\n",
    "    test_predictions['x'] =x_\n",
    "    test_predictions['y'] =y_\n",
    "    test_predictions['width'] =w_\n",
    "    test_predictions['height']=h_\n",
    "    test_predictions['Target'] = t_\n",
    "    test_predictions['area'] = area\n",
    "\n",
    "    return test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = predict()\n",
    "\n",
    "parsed_test= parse_data(test_predictions, test = True)\n",
    "plt.style.use('default')\n",
    "fig=plt.figure(figsize=(12, 20))\n",
    "columns = 1; rows = 8\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    draw(parsed_test[test_predictions['patientId'].unique()[i]])\n",
    "    fig.add_subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKWsQ1xMvWFt"
   },
   "source": [
    "### testing shows that model is not trained enough to make predictions\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5382,
     "status": "ok",
     "timestamp": 1578161209231,
     "user": {
      "displayName": "sahand azad",
      "photoUrl": "https://lh6.googleusercontent.com/-o867s7QeY4M/AAAAAAAAAAI/AAAAAAAAWoc/XLta5OuiE4M/s64/photo.jpg",
      "userId": "02116279255621625687"
     },
     "user_tz": 480
    },
    "id": "ODQ42ulNiZHC",
    "outputId": "b9d08341-ee52-4107-c823-f79d3878e9ca"
   },
   "source": [
    "test_predictions = predict()\n",
    "print(test_predictions)\n",
    "\n",
    "test_predictions['Target'].values[test_predictions['Target'].values > 0.5] = 1\n",
    "parsed_test= parse_data(test_predictions, test = True)\n",
    "plt.style.use('default')\n",
    "fig=plt.figure(figsize=(12, 20))\n",
    "file_name=draw(parsed_test[test_predictions['patientId'].unique()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "RSNA CNN Classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
